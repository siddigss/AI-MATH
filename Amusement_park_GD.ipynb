{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "  Now that we understand the steps for gradient descent, let us do an example:\n",
        "  A new amusement park is about to open in Jeddah. The engineers would like to build a fun wiggly ride that shows you all the cool places in the park. The ride they came up with had the following route:\n",
        "\n",
        "  $$g(x,t)=t \\sin{x}+3t \\cos (2x).$$\n",
        "  They also know that the cool places are located at the points $$(x,y)=\\{(1,-3),(3,6),(5,-7),(7,2),(9,5),(11,-8)\\}.$$\n",
        "  Unfortunately, they do not know what is the best $t$ that would pass along most of the cool places. Can you help them?\n",
        "  play with this graph to better understand the problem:\n",
        "  https://www.desmos.com/calculator/jyp7hitvh2"
      ],
      "metadata": {
        "id": "0Sr42m5Itj1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math"
      ],
      "metadata": {
        "id": "sgMvBcSZtNRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We wanted to find the best $t$ for the engineers. Can you think of a loss function that depends only on $t$ that we would like to minimize?"
      ],
      "metadata": {
        "id": "DgqpvF4fsYlb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In these cases, we usually use the *squared loss function*, which comes in the following form:\n",
        "$$loss(t)=(g(x_1,t)-y_1)^2+(g(x_2,t)-y_2)^2+(g(x_3,t)-y_3)^2+(g(x_4,t)-y_4)^2+(g(x_5,t)-y_5)^2+(g(x_6,t)-y_6)^2$$\n",
        "where $(x_1,y_1)$ stands for the first location $(1,-3)$ and $(x_2,y_2)=(3,6)$ and so on and so forth."
      ],
      "metadata": {
        "id": "BWrA1mTqthCc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To minimize this function we need to calculate its derivative. Can you do that?"
      ],
      "metadata": {
        "id": "schk-wADv81p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "points=[(1,-3),(3,6),(5,-7),(7,2),(9,5),(11,-8)]\n",
        "def Loss(t,points):\n",
        "\n",
        "  loss=0\n",
        "\n",
        "  for point in points:\n",
        "    loss+=(t*math.sin(point[0])+3*t*math.cos(2*point[0])-point[1])**2\n",
        "\n",
        "  return loss\n",
        "\n",
        "def Loss_derivative(t,points):\n",
        "\n",
        "  loss_derivative=0\n",
        "  for point in points:\n",
        "    loss_derivative+=2*(t*math.sin(point[0])+3*t*math.cos(2*point[0])-point[1])*(math.sin(point[0])+3*math.cos(2*point[0]))\n",
        "  return loss_derivative"
      ],
      "metadata": {
        "id": "k4desbhRwGYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code above defines the loss function and the derivative of the loss function. What are the next steps of gradient descent?\n"
      ],
      "metadata": {
        "id": "WvW4u6HXy8JF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate=0.01\n",
        "t=7\n",
        "for i in range(50):\n",
        "  t=t-learning_rate*Loss_derivative(t,points)\n",
        "  print('t=',t,'Loss=',Loss(t,points))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJeGCgYxx883",
        "outputId": "2dcd1286-4eed-4e1a-ca26-634a2efb8c91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t= 2.6014751833810434 Loss= 19.296234176131783\n",
            "t= 2.0951248947961356 Loss= 5.000942050646581\n",
            "t= 2.0368347576616816 Loss= 4.811497959022216\n",
            "t= 2.0301245016121605 Loss= 4.808987407748666\n",
            "t= 2.0293520289698974 Loss= 4.808954137417335\n",
            "t= 2.029263103304671 Loss= 4.8089536965122015\n",
            "t= 2.0292528663415688 Loss= 4.808953690669237\n",
            "t= 2.0292516878807354 Loss= 4.8089536905918076\n",
            "t= 2.029251552218438 Loss= 4.808953690590778\n",
            "t= 2.0292515366012376 Loss= 4.808953690590765\n",
            "t= 2.0292515348034135 Loss= 4.808953690590765\n",
            "t= 2.029251534596451 Loss= 4.808953690590766\n",
            "t= 2.029251534572626 Loss= 4.808953690590767\n",
            "t= 2.0292515345698834 Loss= 4.808953690590766\n",
            "t= 2.0292515345695676 Loss= 4.808953690590766\n",
            "t= 2.0292515345695312 Loss= 4.808953690590767\n",
            "t= 2.029251534569527 Loss= 4.808953690590767\n",
            "t= 2.0292515345695263 Loss= 4.808953690590766\n",
            "t= 2.0292515345695263 Loss= 4.808953690590766\n",
            "t= 2.0292515345695263 Loss= 4.808953690590766\n",
            "t= 2.0292515345695263 Loss= 4.808953690590766\n",
            "t= 2.0292515345695263 Loss= 4.808953690590766\n",
            "t= 2.0292515345695263 Loss= 4.808953690590766\n",
            "t= 2.0292515345695263 Loss= 4.808953690590766\n",
            "t= 2.0292515345695263 Loss= 4.808953690590766\n",
            "t= 2.0292515345695263 Loss= 4.808953690590766\n",
            "t= 2.0292515345695263 Loss= 4.808953690590766\n",
            "t= 2.0292515345695263 Loss= 4.808953690590766\n",
            "t= 2.0292515345695263 Loss= 4.808953690590766\n",
            "t= 2.0292515345695263 Loss= 4.808953690590766\n",
            "t= 2.0292515345695263 Loss= 4.808953690590766\n",
            "t= 2.0292515345695263 Loss= 4.808953690590766\n",
            "t= 2.0292515345695263 Loss= 4.808953690590766\n",
            "t= 2.0292515345695263 Loss= 4.808953690590766\n",
            "t= 2.0292515345695263 Loss= 4.808953690590766\n",
            "t= 2.0292515345695263 Loss= 4.808953690590766\n",
            "t= 2.0292515345695263 Loss= 4.808953690590766\n",
            "t= 2.0292515345695263 Loss= 4.808953690590766\n",
            "t= 2.0292515345695263 Loss= 4.808953690590766\n",
            "t= 2.0292515345695263 Loss= 4.808953690590766\n",
            "t= 2.0292515345695263 Loss= 4.808953690590766\n",
            "t= 2.0292515345695263 Loss= 4.808953690590766\n",
            "t= 2.0292515345695263 Loss= 4.808953690590766\n",
            "t= 2.0292515345695263 Loss= 4.808953690590766\n",
            "t= 2.0292515345695263 Loss= 4.808953690590766\n",
            "t= 2.0292515345695263 Loss= 4.808953690590766\n",
            "t= 2.0292515345695263 Loss= 4.808953690590766\n",
            "t= 2.0292515345695263 Loss= 4.808953690590766\n",
            "t= 2.0292515345695263 Loss= 4.808953690590766\n",
            "t= 2.0292515345695263 Loss= 4.808953690590766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, what if the engineers had a different route function that looked like this:\n",
        "$$g(x,t_1,t_2)=t_1 \\sin x +3t_2 \\cos (2x)$$\n",
        "\n",
        "1. Can you write the loss function? \\\\\n",
        "2. Can you think of a way to write its derivative?"
      ],
      "metadata": {
        "id": "qfsbPDrf4b3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Multi_Loss(t1,t2,points):\n",
        "\n",
        "  loss=0\n",
        "\n",
        "  for point in points:\n",
        "    loss+=(t1*math.sin(point[0])+3*t2*math.cos(2*point[0])-point[1])**2\n",
        "\n",
        "  return loss\n",
        "\n",
        "def Multi_Loss_derivative(t1,t2,points):\n",
        "\n",
        "  t1_loss_derivative=0\n",
        "  t2_loss_derivative=0\n",
        "  for point in points:\n",
        "    t1_loss_derivative+=2*(t1*math.sin(point[0])+3*t2*math.cos(2*point[0])-point[1])*(math.sin(point[0]))\n",
        "    t2_loss_derivative+=2*(t1*math.sin(point[0])+3*t2*math.cos(2*point[0])-point[1])*(3*math.cos(2*point[0]))\n",
        "  return t1_loss_derivative,t2_loss_derivative\n"
      ],
      "metadata": {
        "id": "2Mzo2X9sm6mI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate=0.01\n",
        "t1=7\n",
        "t2=10\n",
        "for i in range(200):\n",
        "  temp1=t1-learning_rate*Multi_Loss_derivative(t1,t2,points)[0]\n",
        "  temp2=t2-learning_rate*Multi_Loss_derivative(t1,t2,points)[1]\n",
        "  t1=temp1\n",
        "  t2=temp2\n",
        "  print('t1=',t1,'t2=',t2, 'Multi_Loss=',Multi_Loss(t1,t2,points))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1FiJIbRoiFG",
        "outputId": "f5748253-c692-4708-cd29-3cd543372724"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t1= 5.702221987860843 t2= 4.790878399534884 Multi_Loss= 394.5327076916003\n",
            "t1= 5.098816596913342 t2= 2.784623726046976 Multi_Loss= 88.84728870046133\n",
            "t1= 4.769573995349589 t2= 2.024059397620877 Multi_Loss= 40.38576553137664\n",
            "t1= 4.550795608832342 t2= 1.7475009238420722 Multi_Loss= 31.054773866430455\n",
            "t1= 4.378621284604312 t2= 1.6585387586894524 Multi_Loss= 27.806400223063104\n",
            "t1= 4.228053186986757 t2= 1.6418434854215889 Multi_Loss= 25.622709962054316\n",
            "t1= 4.089224130784962 t2= 1.6525594427441792 Multi_Loss= 23.732435641885846\n",
            "t1= 3.9581611714795435 t2= 1.6732576282712481 Multi_Loss= 22.008429882624075\n",
            "t1= 3.833190646407523 t2= 1.697182148451542 Multi_Loss= 20.421916977371172\n",
            "t1= 3.7135388338032413 t2= 1.7217299116259874 Multi_Loss= 18.95976504997006\n",
            "t1= 3.598787137736083 t2= 1.7459130183959901 Multi_Loss= 17.611897143899963\n",
            "t1= 3.48865985598626 t2= 1.7693711852643057 Multi_Loss= 16.369330835255955\n",
            "t1= 3.3829413943728266 t2= 1.791987427580736 Multi_Loss= 15.223831937036856\n",
            "t1= 3.2814438680754874 t2= 1.8137385247501583 Multi_Loss= 14.167816546301685\n",
            "t1= 3.183994320323852 t2= 1.8346368593502282 Multi_Loss= 13.194294262250917\n",
            "t1= 3.0904295828689476 t2= 1.8547078167976379 Multi_Loss= 12.296820917118884\n",
            "t1= 3.0005941171586388 t2= 1.8739810234928937 Multi_Loss= 11.469455768642087\n",
            "t1= 2.9143390218990115 t2= 1.8924869694381528 Multi_Loss= 10.706722153023371\n",
            "t1= 2.8315215006313768 t2= 1.9102557251485934 Multi_Loss= 10.003571229224825\n",
            "t1= 2.7520045141692155 t2= 1.927316472396759 Multi_Loss= 9.355348558131173\n",
            "t1= 2.6756565105744503 t2= 1.9436973504943351 Multi_Loss= 8.757763292863652\n",
            "t1= 2.6023511906817722 t2= 1.9594254242264144 Multi_Loss= 8.20685977592469\n",
            "t1= 2.531967292614337 t2= 1.9745266980256497 Multi_Loss= 7.698991355106316\n",
            "t1= 2.4643883886415834 t2= 1.989026147080382 Multi_Loss= 7.230796244830533\n",
            "t1= 2.399502691594052 t2= 2.0029477540134413 Multi_Loss= 6.799175273136875\n",
            "t1= 2.3372028695617986 t2= 2.0163145467497574 Multi_Loss= 6.4012713670152435\n",
            "t1= 2.2773858681989263 t2= 2.029148635906423 Multi_Loss= 6.034450640289248\n",
            "t1= 2.2199527401959096 t2= 2.041471251094136 Multi_Loss= 5.696284958862994\n",
            "t1= 2.1648084815814483 t2= 2.05330277592819 Multi_Loss= 5.384535867923805\n",
            "t1= 2.111861874561192 t2= 2.0646627817049827 Multi_Loss= 5.097139774708458\n",
            "t1= 2.0610253366248568 t2= 2.075570059760101 Multi_Loss= 4.8321942887517535\n",
            "t1= 2.012214775668815 t2= 2.0860426525460474 Multi_Loss= 4.587945629197995\n",
            "t1= 1.9653494508932265 t2= 2.0960978834750272 Multi_Loss= 4.362777015819337\n",
            "t1= 1.920351839243097 t2= 2.105752385573806 Multi_Loss= 4.155197966896413\n",
            "t1= 1.8771475071721524 t2= 2.1150221289971394 Multi_Loss= 3.963834433119682\n",
            "t1= 1.8356649875173217 t2= 2.1239224474449236 Multi_Loss= 3.7874197022037785\n",
            "t1= 1.79583566128013 t2= 2.132468063526636 Multi_Loss= 3.624786014008812\n",
            "t1= 1.75759364411944 t2= 2.1406731131149614 Multi_Loss= 3.4748568306658107\n",
            "t1= 1.7208756773677718 t2= 2.148551168728871 Multi_Loss= 3.336639710539061\n",
            "t1= 1.685621023390929 t2= 2.1561152619848283 Multi_Loss= 3.2092197388553187\n",
            "t1= 1.6517713651178314 t2= 2.16337790515325 Multi_Loss= 3.0917534715145094\n",
            "t1= 1.6192707095743646 t2= 2.1703511118558887 Multi_Loss= 2.9834633519936014\n",
            "t1= 1.5880652952616716 t2= 2.177046416938362 Multi_Loss= 2.8836325643869043\n",
            "t1= 1.5581035032256778 t2= 2.1834748955507095 Multi_Loss= 2.7916002885129303\n",
            "t1= 1.529335771670741 t2= 2.189647181467537 Multi_Loss= 2.706757325679538\n",
            "t1= 1.5017145139761838 t2= 2.1955734846780492 Multi_Loss= 2.628542066152485\n",
            "t1= 1.4751940399800962 t2= 2.2012636082750747 Multi_Loss= 2.556436771634451\n",
            "t1= 1.449730480400195 t2= 2.206726964671014 Multi_Loss= 2.4899641481467785\n",
            "t1= 1.4252817142667227 t2= 2.211972591167537 Multi_Loss= 2.428684186628435\n",
            "t1= 1.4018072992473463 t2= 2.217009164904787 Multi_Loss= 2.3721912503388656\n",
            "t1= 1.3792684047488015 t2= 2.221845017214816 Multi_Loss= 2.3201113897850703\n",
            "t1= 1.3576277476846228 t2= 2.2264881474029936 Multi_Loss= 2.2720998673993313\n",
            "t1= 1.3368495308027066 t2= 2.230946235980194 Multi_Loss= 2.227838875582438\n",
            "t1= 1.3168993834706932 t2= 2.2352266573676385 Multi_Loss= 2.18703543300723\n",
            "t1= 1.297744304821214 t2= 2.2393364920954175 Multi_Loss= 2.1494194452571986\n",
            "t1= 1.279352609162959 t2= 2.2432825385148663 Multi_Loss= 2.114741916962804\n",
            "t1= 1.2616938735672651 t2= 2.2470713240441715 Multi_Loss= 2.0827733036008538\n",
            "t1= 1.2447388875435235 t2= 2.2507091159658077 Multi_Loss= 2.0533019920468845\n",
            "t1= 1.228459604720161 t2= 2.2542019317936672 Multi_Loss= 2.026132899822665\n",
            "t1= 1.2128290964512702 t2= 2.2575555492270296 Multi_Loss= 2.001086183766735\n",
            "t1= 1.1978215072721419 t2= 2.2607755157078406 Multi_Loss= 1.9779960495800983\n",
            "t1= 1.1834120121300191 t2= 2.2638671575971037 Multi_Loss= 1.956709654366993\n",
            "t1= 1.1695767753193247 t2= 2.266835588985569 Multi_Loss= 1.9370860949062287\n",
            "t1= 1.1562929110534321 t2= 2.269685720153292 Multi_Loss= 1.918995474956024\n",
            "t1= 1.1435384456077626 t2= 2.2724222656920543 Multi_Loss= 1.9023180454184778\n",
            "t1= 1.1312922809715835 t2= 2.275049752304083 Multi_Loss= 1.886943411672072\n",
            "t1= 1.1195341599483835 t2= 2.2775725262899726 Multi_Loss= 1.87276980282522\n",
            "t1= 1.108244632647095 t2= 2.279994760738188 Multi_Loss= 1.859703398053753\n",
            "t1= 1.0974050243087339 t2= 2.282320462428049 Multi_Loss= 1.8476577055631145\n",
            "t1= 1.086997404415237 t2= 2.2845534784576116 Multi_Loss= 1.8365529900643354\n",
            "t1= 1.0770045570293978 t2= 2.2866975026074075 Multi_Loss= 1.826315744974053\n",
            "t1= 1.067409952316838 t2= 2.2887560814505727 Multi_Loss= 1.8168782058448387\n",
            "t1= 1.0581977192029086 t2= 2.290732620219473 Multi_Loss= 1.8081779018050383\n",
            "t1= 1.0493526191192868 t2= 2.292630388438521 Multi_Loss= 1.8001572420389043\n",
            "t1= 1.0408600207968466 t2= 2.2944525253325185 Multi_Loss= 1.792763134569811\n",
            "t1= 1.0327058760631014 t2= 2.296202045019455 Multi_Loss= 1.7859466348230753\n",
            "t1= 1.0248766966041865 t2= 2.2978818414963618 Multi_Loss= 1.7796626216421136\n",
            "t1= 1.0173595316529405 t2= 2.299494693426464 Multi_Loss= 1.7738694986133288\n",
            "t1= 1.0101419465661794 t2= 2.301043268735554 Multi_Loss= 1.7685289187227096\n",
            "t1= 1.003212002255725 t2= 2.302530129025186 Multi_Loss= 1.7636055305215002\n",
            "t1= 0.9965582354391631 t2= 2.3039577338099875 Multi_Loss= 1.7590667441207186\n",
            "t1= 0.9901696396776664 t2= 2.3053284445861113 Multi_Loss= 1.754882515465573\n",
            "t1= 0.9840356471695093 t2= 2.306644528737541 Multi_Loss= 1.751025147461755\n",
            "t1= 0.9781461112691643 t2= 2.3079081632867204 Multi_Loss= 1.747469106637219\n",
            "t1= 0.9724912897030593 t2= 2.309121438495716 Multi_Loss= 1.7441908541258577\n",
            "t1= 0.9670618284542345 t2= 2.3102863613238536 Multi_Loss= 1.741168689854264\n",
            "t1= 0.9618487462892396 t2= 2.311404858747567 Multi_Loss= 1.7383826089002046\n",
            "t1= 0.9568434199016775 t2= 2.312478780947935 Multi_Loss= 1.7358141690719868\n",
            "t1= 0.9520375696478194 t2= 2.313509904371192 Multi_Loss= 1.7334463688321717\n",
            "t1= 0.9474232458506937 t2= 2.3144999346672646 Multi_Loss= 1.731263534757541\n",
            "t1= 0.9429928156499967 t2= 2.3154505095112015 Multi_Loss= 1.7292512177904042\n",
            "t1= 0.9387389503760697 t2= 2.316363201312159 Multi_Loss= 1.727396097594469\n",
            "t1= 0.9346546134270585 t2= 2.31723951981443 Multi_Loss= 1.7256858943821647\n",
            "t1= 0.9307330486292015 t2= 2.3180809145948116 Multi_Loss= 1.7241092876297925\n",
            "t1= 0.9269677690609929 t2= 2.318888777460446 Multi_Loss= 1.7226558411424158\n",
            "t1= 0.9233525463227338 t2= 2.3196644447511026 Multi_Loss= 1.7213159339724817\n",
            "t1= 0.9198814002337214 t2= 2.3204091995497054 Multi_Loss= 1.7200806967349016\n",
            "t1= 0.916548588940034 t2= 2.3211242738047675 Multi_Loss= 1.7189419528970102\n",
            "t1= 0.9133485994165474 t2= 2.3218108503682373 Multi_Loss= 1.7178921646548158\n",
            "t1= 0.9102761383474738 t2= 2.322470064952134 Multi_Loss= 1.7169243830372303\n",
            "t1= 0.9073261233703348 t2= 2.3231030080072044 Multi_Loss= 1.7160322019080347\n",
            "t1= 0.9044936746688877 t2= 2.323710726526709 Multi_Loss= 1.7152097155610857\n",
            "t1= 0.9017741069010963 t2= 2.3242942257783255 Multi_Loss= 1.7144514796280668\n",
            "t1= 0.8991629214487943 t2= 2.3248544709670256 Multi_Loss= 1.7137524750400221\n",
            "t1= 0.8966557989762218 t2= 2.325392388831688 Multi_Loss= 1.7131080748041179\n",
            "t1= 0.8942485922851244 t2= 2.325908869178078 Multi_Loss= 1.712514013375721\n",
            "t1= 0.8919373194545959 t2= 2.326404766350734 Multi_Loss= 1.711966358423024\n",
            "t1= 0.889718157254318 t2= 2.3268809006461955 Multi_Loss= 1.7114614847973748\n",
            "t1= 0.8875874348203006 t2= 2.3273380596699105 Multi_Loss= 1.71099605053695\n",
            "t1= 0.8855416275826608 t2= 2.327776999639067 Multi_Loss= 1.7105669747449688\n",
            "t1= 0.8835773514353973 t2= 2.3281984466335013 Multi_Loss= 1.7101714171959879\n",
            "t1= 0.8816913571385155 t2= 2.3286030977967545 Multi_Loss= 1.7098067595353152\n",
            "t1= 0.8798805249432431 t2= 2.3289916224892653 Multi_Loss= 1.7094705879470582\n",
            "t1= 0.8781418594314454 t2= 2.3293646633956033 Multi_Loss= 1.709160677176112\n",
            "t1= 0.8764724845607055 t2= 2.3297228375875756 Multi_Loss= 1.708874975798293\n",
            "t1= 0.8748696389068704 t2= 2.3300667375449677 Multi_Loss= 1.7086115926411372\n",
            "t1= 0.8733306710961958 t2= 2.330396932135603 Multi_Loss= 1.7083687842654762\n",
            "t1= 0.8718530354195315 t2= 2.3307139675563437 Multi_Loss= 1.7081449434248992\n",
            "t1= 0.8704342876212954 t2= 2.331018368236594 Multi_Loss= 1.7079385884267482\n",
            "t1= 0.8690720808562666 t2= 2.331310637705792 Multi_Loss= 1.7077483533242002\n",
            "t1= 0.8677641618075133 t2= 2.331591259426332 Multi_Loss= 1.7075729788745122\n",
            "t1= 0.86650836695903 t2= 2.3318606975932905 Multi_Loss= 1.7074113042035812\n",
            "t1= 0.865302619016923 t2= 2.332119397902284 Multi_Loss= 1.7072622591216629\n",
            "t1= 0.864144923473219 t2= 2.3323677882867235 Multi_Loss= 1.7071248570393425\n",
            "t1= 0.8630333653066177 t2= 2.332606279625686 Multi_Loss= 1.7069981884369105\n",
            "t1= 0.8619661058147264 t2= 2.3328352664235785 Multi_Loss= 1.7068814148438838\n",
            "t1= 0.860941379572541 t2= 2.3330551274627145 Multi_Loss= 1.7067737632888278\n",
            "t1= 0.859957491512138 t2= 2.3332662264298802 Multi_Loss= 1.7066745211827548\n",
            "t1= 0.8590128141187505 t2= 2.3334689125179375 Multi_Loss= 1.7065830316022002\n",
            "t1= 0.8581057847385872 t2= 2.333663521003443 Multi_Loss= 1.7064986889407936\n",
            "t1= 0.8572349029939429 t2= 2.333850373801253 Multi_Loss= 1.706420934900495\n",
            "t1= 0.8563987283013235 t2= 2.334029779997025 Multi_Loss= 1.7063492547960046\n",
            "t1= 0.8555958774884812 t2= 2.3342020363584957 Multi_Loss= 1.706283174147848\n",
            "t1= 0.8548250225064173 t2= 2.334367427826385 Multi_Loss= 1.7062222555416044\n",
            "t1= 0.8540848882325675 t2= 2.334526227985734 Multi_Loss= 1.7061660957324882\n",
            "t1= 0.8533742503615368 t2= 2.3346786995184634 Multi_Loss= 1.7061143229761153\n",
            "t1= 0.852691933379895 t2= 2.3348250946378895 Multi_Loss= 1.7060665945677607\n",
            "t1= 0.8520368086216807 t2= 2.334965655505929 Multi_Loss= 1.7060225945738692\n",
            "t1= 0.8514077924014005 t2= 2.3351006146336752 Multi_Loss= 1.705982031740765\n",
            "t1= 0.8508038442214324 t2= 2.3352301952660097 Multi_Loss= 1.705944637566726\n",
            "t1= 0.8502239650508693 t2= 2.335354611750886 Multi_Loss= 1.7059101645246524\n",
            "t1= 0.8496671956729556 t2= 2.335474069893898 Multi_Loss= 1.7058783844235985\n",
            "t1= 0.8491326150983829 t2= 2.3355887672987157 Multi_Loss= 1.7058490868982816\n",
            "t1= 0.84861933904182 t2= 2.335698893693955 Multi_Loss= 1.7058220780165831\n",
            "t1= 0.848126518459158 t2= 2.3358046312470213 Multi_Loss= 1.7057971789958364\n",
            "t1= 0.8476533381430496 t2= 2.3359061548654427 Multi_Loss= 1.7057742250194026\n",
            "t1= 0.8471990153744202 t2= 2.3360036324861984 Multi_Loss= 1.7057530641456626\n",
            "t1= 0.8467627986277209 t2= 2.336097225353512 Multi_Loss= 1.7057335563022793\n",
            "t1= 0.846343966327779 t2= 2.336187088285579 Multi_Loss= 1.7057155723589794\n",
            "t1= 0.8459418256561932 t2= 2.33627336993066 Multi_Loss= 1.7056989932727997\n",
            "t1= 0.8455557114052966 t2= 2.3363562130129707 Multi_Loss= 1.705683709300092\n",
            "t1= 0.8451849848777917 t2= 2.336435754568771 Multi_Loss= 1.7056696192700882\n",
            "t1= 0.844829032830239 t2= 2.336512126173045 Multi_Loss= 1.705656629915207\n",
            "t1= 0.8444872664586507 t2= 2.3365854541571496 Multi_Loss= 1.7056446552536768\n",
            "t1= 0.8441591204245101 t2= 2.336655859817788 Multi_Loss= 1.7056336160203902\n",
            "t1= 0.8438440519196079 t2= 2.3367234596176516 Multi_Loss= 1.7056234391422198\n",
            "t1= 0.8435415397681466 t2= 2.3367883653780717 Multi_Loss= 1.7056140572543101\n",
            "t1= 0.8432510835646294 t2= 2.336850684463989 Multi_Loss= 1.7056054082541674\n",
            "t1= 0.8429722028461061 t2= 2.3369105199615547 Multi_Loss= 1.7055974348905745\n",
            "t1= 0.8427044362974065 t2= 2.3369679708486495 Multi_Loss= 1.7055900843846283\n",
            "t1= 0.8424473409880496 t2= 2.337023132158612 Multi_Loss= 1.7055833080803735\n",
            "t1= 0.8422004916395619 t2= 2.337076095137439 Multi_Loss= 1.7055770611227201\n",
            "t1= 0.8419634799219959 t2= 2.3371269473947214 Multi_Loss= 1.7055713021605405\n",
            "t1= 0.8417359137784848 t2= 2.337175773048564 Multi_Loss= 1.7055659930729468\n",
            "t1= 0.8415174167767148 t2= 2.337222652864733 Multi_Loss= 1.7055610987169492\n",
            "t1= 0.8413076274862435 t2= 2.3372676643902546 Multi_Loss= 1.7055565866948348\n",
            "t1= 0.8411061988806339 t2= 2.3373108820816904 Multi_Loss= 1.7055524271397113\n",
            "t1= 0.8409127977634142 t2= 2.3373523774283025 Multi_Loss= 1.7055485925178107\n",
            "t1= 0.8407271042169162 t2= 2.337392219070307 Multi_Loss= 1.705545057446223\n",
            "t1= 0.8405488110730774 t2= 2.3374304729124176 Multi_Loss= 1.7055417985248893\n",
            "t1= 0.8403776234053346 t2= 2.337467202232862 Multi_Loss= 1.7055387941816957\n",
            "t1= 0.8402132580407654 t2= 2.3375024677880556 Multi_Loss= 1.7055360245296862\n",
            "t1= 0.8400554430916738 t2= 2.337536327913102 Multi_Loss= 1.7055334712354169\n",
            "t1= 0.8399039175058419 t2= 2.3375688386182887 Multi_Loss= 1.705531117397607\n",
            "t1= 0.8397584306347069 t2= 2.3376000536817383 Multi_Loss= 1.7055289474352533\n",
            "t1= 0.8396187418187459 t2= 2.3376300247383663 Multi_Loss= 1.7055269469845042\n",
            "t1= 0.8394846199893851 t2= 2.3376588013652935 Multi_Loss= 1.705525102803569\n",
            "t1= 0.8393558432867742 t2= 2.337686431163855 Multi_Loss= 1.7055234026850707\n",
            "t1= 0.839232198692793 t2= 2.337712959838341 Multi_Loss= 1.705521835375243\n",
            "t1= 0.8391134816786839 t2= 2.3377384312715987 Multi_Loss= 1.7055203904994283\n",
            "t1= 0.8389994958667274 t2= 2.3377628875976217 Multi_Loss= 1.7055190584934146\n",
            "t1= 0.8388900527054006 t2= 2.3377863692712486 Multi_Loss= 1.7055178305401162\n",
            "t1= 0.8387849711574815 t2= 2.3378089151350787 Multi_Loss= 1.7055166985112156\n",
            "t1= 0.8386840774005833 t2= 2.3378305624837274 Multi_Loss= 1.7055156549133572\n",
            "t1= 0.8385872045396232 t2= 2.3378513471255156 Multi_Loss= 1.7055146928385494\n",
            "t1= 0.8384941923307503 t2= 2.3378713034417036 Multi_Loss= 1.705513805918427\n",
            "t1= 0.8384048869162753 t2= 2.3378904644433627 Multi_Loss= 1.7055129882821138\n",
            "t1= 0.8383191405701645 t2= 2.3379088618259822 Multi_Loss= 1.7055122345173395\n",
            "t1= 0.8382368114536761 t2= 2.3379265260218984 Multi_Loss= 1.7055115396346374\n",
            "t1= 0.8381577633807356 t2= 2.3379434862506336 Multi_Loss= 1.7055108990342964\n",
            "t1= 0.8380818655926607 t2= 2.337959770567232 Multi_Loss= 1.7055103084759249\n",
            "t1= 0.8380089925418657 t2= 2.337975405908666 Multi_Loss= 1.7055097640503818\n",
            "t1= 0.8379390236841837 t2= 2.3379904181383946 Multi_Loss= 1.7055092621538912\n",
            "t1= 0.8378718432794676 t2= 2.338004832089148 Multi_Loss= 1.7055087994642\n",
            "t1= 0.8378073402001356 t2= 2.3380186716040012 Multi_Loss= 1.7055083729185794\n",
            "t1= 0.8377454077473484 t2= 2.338031959575818 Multi_Loss= 1.7055079796935537\n",
            "t1= 0.8376859434745112 t2= 2.338044717985117 Multi_Loss= 1.7055076171862018\n",
            "t1= 0.8376288490178099 t2= 2.3380569679364336 Multi_Loss= 1.705507282996949\n",
            "t1= 0.8375740299335013 t2= 2.338068729693227 Multi_Loss= 1.7055069749136575\n",
            "t1= 0.8375213955416871 t2= 2.338080022711403 Multi_Loss= 1.7055066908970016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Engineers think it is a good idea to come up with a new route that looks like this:\n",
        "$$g(x,t_1,t_2,t_3)=t_1 \\sin x +3t_2 \\cos (2t_3x).$$\n",
        "Let us compute the loss function and come up with its derivative.\n",
        "We can see that the loss function with respect to one point is:\n",
        "$$f_i(t_1,t_2,t_3)=(t_1 \\sin(x_i)+3t_2\\cos (2t_3x_i)-y_i)^2$$\n",
        "\n",
        "So if we take the point $(1,-3)$ the loss for that point is:\n",
        "$$f_i(t_1,t_2,t_3)=(t_1 \\sin(1)+3t_2\\cos (2t_3×1)-(-3))^2$$\n",
        "To get the total loss, we sum up the losses overall of the points.\n",
        "\n"
      ],
      "metadata": {
        "id": "MQgxdoZ0vUwN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Multi_Loss_oscilation(t1,t2,t3,points):\n",
        "\n",
        "  loss=0\n",
        "  #this is the computation for the loss function.\n",
        "  for point in points:\n",
        "    loss+=(t1*math.sin(point[0])+3*t2*math.cos(2*t3*point[0])-point[1])**2\n",
        "\n",
        "  return loss"
      ],
      "metadata": {
        "id": "kCoPZip7pMjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the derivative of the loss function, we need to calculate the gradient. That is, the partial derivatives $\\big(\\frac{∂f}{∂t_1},\\frac{∂f}{∂t_2},\\frac{∂f}{∂t_3}\\big)$. for the first partial derivative we have:\n",
        "$$\\frac{∂f}{∂t_1}=Σ\\bigg[2(t_1\\sin(x_i)+3t_2\\cos(2*t_3x_i)-y_i)×\\sin(x_i)\\bigg].$$\n",
        "Can you calculate the rest?"
      ],
      "metadata": {
        "id": "PdI9vV3Zw4uN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Multi_Loss_derivative_Oscilation(t1,t2,t3,points):\n",
        "\n",
        "  t1_loss_derivative=0\n",
        "  t2_loss_derivative=0\n",
        "  t3_loss_derivative=0\n",
        "  for point in points:\n",
        "    t1_loss_derivative+=2*(t1*math.sin(point[0])+3*t2*math.cos(2*point[0]*t3)-point[1])*(math.sin(point[0]))\n",
        "    t2_loss_derivative+=2*(t1*math.sin(point[0])+3*t2*math.cos(2*point[0]*t3)-point[1])*(3*math.cos(2*point[0]*t3))\n",
        "    t3_loss_derivative+=2*(t1*math.sin(point[0])+3*t2*math.cos(2*point[0]*t3)-point[1])*(-3*t2*math.sin(2*point[0]*t3)*2*point[0])\n",
        "\n",
        "  return t1_loss_derivative,t2_loss_derivative,t3_loss_derivative"
      ],
      "metadata": {
        "id": "7nX7GIFGyN3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have the loss derivatives, we can apply the gradient descent!"
      ],
      "metadata": {
        "id": "IF7lj3pOy9hv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate=0.001\n",
        "t1=7\n",
        "t2=10\n",
        "t3=1\n",
        "for i in range(200):\n",
        "  temp1=t1-learning_rate*Multi_Loss_derivative_Oscilation(t1,t2,t3,points)[0]\n",
        "  temp2=t2-learning_rate*Multi_Loss_derivative_Oscilation(t1,t2,t3,points)[1]\n",
        "  temp3 = t3-learning_rate*Multi_Loss_derivative_Oscilation(t1,t2,t3,points)[2]\n",
        "  t1=temp1\n",
        "  t2=temp2\n",
        "  t3=temp3\n",
        "  print('t1=',t1,'t2=',t2, 't3=',t3, 'Multi_Loss=',Multi_Loss(t1,t2,points))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uokIjv5py8sg",
        "outputId": "1a844039-9a1d-4b0b-9e6b-97cca1103d62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t1= 6.8702221987860845 t2= 9.479087839953488 t3= -2.0993136707304805 Multi_Loss= 2117.7879050108304\n",
            "t1= 6.80381242500952 t2= 9.036553191432583 t3= 10.633179031549734 Multi_Loss= 1899.3760366033928\n",
            "t1= 6.9090058998922705 t2= 8.63468312851039 t3= 10.064316316143035 Multi_Loss= 1730.237793516303\n",
            "t1= 6.962647854164794 t2= 8.193736509860111 t3= 5.9914196740738985 Multi_Loss= 1547.7713626264062\n",
            "t1= 6.928247045815875 t2= 7.673150130555803 t3= 7.359831120999823 Multi_Loss= 1336.313262625689\n",
            "t1= 6.934623751700064 t2= 7.377844492996604 t3= 7.4741292199055485 Multi_Loss= 1226.159741327423\n",
            "t1= 7.032336069146034 t2= 7.049757418914286 t3= 10.430877639656718 Multi_Loss= 1118.3388064782275\n",
            "t1= 6.940070588943987 t2= 6.698758365307682 t3= 11.578780912890034 Multi_Loss= 991.2245148464278\n",
            "t1= 6.846314611120345 t2= 6.384014741726507 t3= 13.875919247183742 Multi_Loss= 883.1153993615997\n",
            "t1= 6.8393190681741105 t2= 6.0764024498731875 t3= 18.57666936101492 Multi_Loss= 790.7683480136013\n",
            "t1= 6.820496379960784 t2= 5.695704754864714 t3= 22.706265111839844 Multi_Loss= 683.4291025042207\n",
            "t1= 6.7992237774164614 t2= 5.377398467678894 t3= 34.72831293987507 Multi_Loss= 599.9160510675447\n",
            "t1= 6.75811937789052 t2= 5.0212763826560955 t3= 36.56396622436077 Multi_Loss= 512.4956963270663\n",
            "t1= 6.8190947859156275 t2= 4.795404723036897 t3= 39.55723230276867 Multi_Loss= 466.94610369019506\n",
            "t1= 6.8183857773436 t2= 4.55193795594266 t3= 39.00763240728551 Multi_Loss= 416.5413392733574\n",
            "t1= 6.810345985191569 t2= 4.341880118393987 t3= 41.309802483616984 Multi_Loss= 375.38342007406254\n",
            "t1= 6.762151749959837 t2= 4.041047481812724 t3= 42.04250104698003 Multi_Loss= 318.8615999647064\n",
            "t1= 6.8065765766940975 t2= 3.885552780046363 t3= 41.98291264762323 Multi_Loss= 295.79403457940083\n",
            "t1= 6.853841392849774 t2= 3.722078320455187 t3= 40.44016668431186 Multi_Loss= 272.9399880235044\n",
            "t1= 6.782222666096747 t2= 3.4594012974986583 t3= 42.94375464403517 Multi_Loss= 231.43713669870755\n",
            "t1= 6.748408317276477 t2= 3.346068922360266 t3= 40.88913040466314 Multi_Loss= 214.77856211909642\n",
            "t1= 6.72900805433392 t2= 3.0762819734785807 t3= 47.34152909630436 Multi_Loss= 181.3960208489652\n",
            "t1= 6.712158039566072 t2= 2.8926311320416964 t3= 47.69952848063566 Multi_Loss= 161.01899016370652\n",
            "t1= 6.735960962501083 t2= 2.66033206078326 t3= 50.18658682937869 Multi_Loss= 140.07330487509867\n",
            "t1= 6.712202562752471 t2= 2.509898097672434 t3= 48.422759643149355 Multi_Loss= 126.54870632344307\n",
            "t1= 6.704250889588762 t2= 2.4051404113010983 t3= 48.955598944307646 Multi_Loss= 118.29918342804442\n",
            "t1= 6.695247628765383 t2= 2.311917101663546 t3= 48.37256192026887 Multi_Loss= 111.44242479343703\n",
            "t1= 6.700054292567674 t2= 2.223770883058732 t3= 47.6212066117543 Multi_Loss= 105.93489070544105\n",
            "t1= 6.6857241136983525 t2= 2.0322990186157357 t3= 47.17537787217869 Multi_Loss= 94.65079624673413\n",
            "t1= 6.669567053461116 t2= 1.8630820945705509 t3= 49.56465784750276 Multi_Loss= 86.4072276868917\n",
            "t1= 6.65774110431993 t2= 1.750623779999831 t3= 48.62892275861009 Multi_Loss= 81.85901153456011\n",
            "t1= 6.653968648053741 t2= 1.6871162290420698 t3= 47.49343291690658 Multi_Loss= 79.71961988660013\n",
            "t1= 6.620249714256038 t2= 1.558087609715416 t3= 47.0325900243256 Multi_Loss= 75.37470737151821\n",
            "t1= 6.601213554825295 t2= 1.463965883949941 t3= 46.84656169877046 Multi_Loss= 73.04051274980243\n",
            "t1= 6.589009341025697 t2= 1.3430727137884544 t3= 47.09136395709405 Multi_Loss= 71.1831785396005\n",
            "t1= 6.577011901684142 t2= 1.191258541251416 t3= 46.07385910816335 Multi_Loss= 70.19290007477383\n",
            "t1= 6.562248308184181 t2= 1.2109767638104756 t3= 45.86176956850684 Multi_Loss= 69.85011808261466\n",
            "t1= 6.558152429504856 t2= 1.1789627227550123 t3= 46.01506261258813 Multi_Loss= 69.75045079377995\n",
            "t1= 6.560142104568125 t2= 1.1884590885843667 t3= 46.572010891294184 Multi_Loss= 69.79180113355879\n",
            "t1= 6.562024752894761 t2= 1.040017429262504 t3= 46.23422949034365 Multi_Loss= 70.52512369150506\n",
            "t1= 6.550663477620122 t2= 0.9714847270582158 t3= 45.63303354834279 Multi_Loss= 71.03808467341644\n",
            "t1= 6.545667457473369 t2= 0.9569393976931869 t3= 45.7532955492204 Multi_Loss= 71.1306975574947\n",
            "t1= 6.539060185106423 t2= 0.9372648309803245 t3= 45.98146850708365 Multi_Loss= 71.28175959016936\n",
            "t1= 6.543559971949298 t2= 0.9421259692593225 t3= 46.333388384741234 Multi_Loss= 71.30144223766914\n",
            "t1= 6.53418825412722 t2= 0.9400661371456931 t3= 46.71174967668865 Multi_Loss= 71.13852474328498\n",
            "t1= 6.5094435721606345 t2= 0.8319095635394662 t3= 47.07738899615842 Multi_Loss= 72.643760434661\n",
            "t1= 6.49799634979768 t2= 0.7393969845460894 t3= 46.62349396899241 Multi_Loss= 74.70306219202816\n",
            "t1= 6.487962282776835 t2= 0.6207415257634407 t3= 46.766754696214086 Multi_Loss= 78.19273048894843\n",
            "t1= 6.47106843812488 t2= 0.5493873827718849 t3= 46.83968053131314 Multi_Loss= 80.53154485280821\n",
            "t1= 6.460754089308308 t2= 0.48045256555176863 t3= 46.87077780102537 Multi_Loss= 83.19155570127046\n",
            "t1= 6.45128841770886 t2= 0.42005082547638584 t3= 46.92889888972158 Multi_Loss= 85.75932381474675\n",
            "t1= 6.4406448587660154 t2= 0.36715448352665214 t3= 46.9458491621714 Multi_Loss= 88.16360103857826\n",
            "t1= 6.429771400787096 t2= 0.3170771232803553 t3= 46.96369967422945 Multi_Loss= 90.59347978193661\n",
            "t1= 6.418850843872573 t2= 0.2707707613463748 t3= 46.985110463426615 Multi_Loss= 92.97266620882706\n",
            "t1= 6.4080798749972905 t2= 0.22944665959683253 t3= 47.00343437155772 Multi_Loss= 95.20076481405498\n",
            "t1= 6.397670832912296 t2= 0.19230960020948218 t3= 47.00973441495469 Multi_Loss= 97.28994450775231\n",
            "t1= 6.387616029882451 t2= 0.15739862870045748 t3= 47.009897985279224 Multi_Loss= 99.33360846846122\n",
            "t1= 6.377863617611568 t2= 0.1241884276262669 t3= 47.00880945167363 Multi_Loss= 101.35031126249669\n",
            "t1= 6.368395209261208 t2= 0.0925774516700612 t3= 47.0074703895598 Multi_Loss= 103.33573532550837\n",
            "t1= 6.359199750691237 t2= 0.06251274257276274 t3= 47.0061741940257 Multi_Loss= 105.28362983608841\n",
            "t1= 6.350267417229523 t2= 0.03394870469739973 t3= 47.00509111337761 Multi_Loss= 107.18811237221097\n",
            "t1= 6.341588346379631 t2= 0.006837120352905575 t3= 47.004375939675896 Multi_Loss= 109.044262398914\n",
            "t1= 6.333152320634164 t2= -0.018879223617638895 t3= 47.00420168749354 Multi_Loss= 110.84856670208818\n",
            "t1= 6.324948706211989 t2= -0.04327323261418131 t3= 47.00478535724756 Multi_Loss= 112.59944813601363\n",
            "t1= 6.316966363659598 t2= -0.06644266254846251 t3= 47.00642050648549 Multi_Loss= 114.29803212968739\n",
            "t1= 6.3091931802639225 t2= -0.0885246928479042 t3= 47.009515240613915 Multi_Loss= 115.94939438427109\n",
            "t1= 6.301614571289677 t2= -0.10971875184286906 t3= 47.01460948873588 Multi_Loss= 117.5645532972239\n",
            "t1= 6.294209756666436 t2= -0.1303117770713307 t3= 47.02227826283176 Multi_Loss= 119.16279964589928\n",
            "t1= 6.286944591016618 t2= -0.15066002090938835 t3= 47.032695917249114 Multi_Loss= 120.77062609476953\n",
            "t1= 6.279764284385481 t2= -0.17099583467236792 t3= 47.04467935810981 Multi_Loss= 122.40598166680445\n",
            "t1= 6.2726043385528145 t2= -0.19102740095311777 t3= 47.05519311516059 Multi_Loss= 124.04372474148089\n",
            "t1= 6.26543518923206 t2= -0.20999872819964044 t3= 47.061510911298875 Multi_Loss= 125.61774740848193\n",
            "t1= 6.258286208716622 t2= -0.22752874600097017 t3= 47.063587007477985 Multi_Loss= 127.09133408524661\n",
            "t1= 6.2512093581647825 t2= -0.2438195556285138 t3= 47.06287519987925 Multi_Loss= 128.4776722055562\n",
            "t1= 6.244247064867979 t2= -0.2592202241733606 t3= 47.06084895619324 Multi_Loss= 129.8040499231362\n",
            "t1= 6.237423689398799 t2= -0.27396903394792577 t3= 47.058585764366626 Multi_Loss= 131.08925609089502\n",
            "t1= 6.2307458915162615 t2= -0.2881593681277804 t3= 47.056628112254636 Multi_Loss= 132.33984868903306\n",
            "t1= 6.224208891321897 t2= -0.30180356817351733 t3= 47.05506360606518 Multi_Loss= 133.55532276830485\n",
            "t1= 6.217804588811678 t2= -0.3148979031051559 t3= 47.0537955896346 Multi_Loss= 134.733781991383\n",
            "t1= 6.211525819525363 t2= -0.3274473053946985 t3= 47.05273551560962 Multi_Loss= 135.87419296852374\n",
            "t1= 6.205366675841619 t2= -0.33946434591916297 t3= 47.05183220570375 Multi_Loss= 136.97632347885354\n",
            "t1= 6.199321959044288 t2= -0.3509648979600965 t3= 47.051052133595675 Multi_Loss= 138.04035517156493\n",
            "t1= 6.19338694706429 t2= -0.361966323964373 t3= 47.05037148631093 Multi_Loss= 139.066716551407\n",
            "t1= 6.1875572806232375 t2= -0.37248660469626704 t3= 47.04977268125113 Multi_Loss= 140.05599837466747\n",
            "t1= 6.181828892634422 t2= -0.3825438471901748 t3= 47.04924227544813 Multi_Loss= 141.0089020758011\n",
            "t1= 6.176197963381784 t2= -0.3921560030439313 t3= 47.048769776456396 Multi_Loss= 141.92620693104064\n",
            "t1= 6.170660888112745 t2= -0.4013406947556462 t3= 47.04834681077584 Multi_Loss= 142.808747044678\n",
            "t1= 6.165214253910515 t2= -0.41011511307675264 t3= 47.04796661564195 Multi_Loss= 143.65739507120378\n",
            "t1= 6.159854821030477 t2= -0.41849595241084114 t3= 47.04762362977023 Multi_Loss= 144.47304973704672\n",
            "t1= 6.15457950882073 t2= -0.42649937653039033 t3= 47.04731325895736 Multi_Loss= 145.25662656289637\n",
            "t1= 6.149385383059649 t2= -0.43414099760448827 t3= 47.04703162976872 Multi_Loss= 146.0090501919664\n",
            "t1= 6.144269646600177 t2= -0.44143587227315984 t3= 47.04677550391438 Multi_Loss= 146.7312487435933\n",
            "t1= 6.139229629355606 t2= -0.4483984983766971 t3= 47.04654206929598 Multi_Loss= 147.42414856965684\n",
            "t1= 6.134262782417529 t2= -0.45504282788871914 t3= 47.04632900104431 Multi_Loss= 148.08867098581334\n",
            "t1= 6.129366668090874 t2= -0.46138226655761805 t3= 47.04613414230242 Multi_Loss= 148.72572798417008\n",
            "t1= 6.1245389589588015 t2= -0.4674297044928581 t3= 47.04595589044078 Multi_Loss= 149.33622141886076\n",
            "t1= 6.119777422547152 t2= -0.47319749820214413 t3= 47.04579233567295 Multi_Loss= 149.9210375223888\n",
            "t1= 6.1150799345300735 t2= -0.47869754680386917 t3= 47.04564280954667 Multi_Loss= 150.48105138891185\n",
            "t1= 6.110444437251147 t2= -0.4839411882694894 t3= 47.0455046575882 Multi_Loss= 151.0171131513622\n",
            "t1= 6.105869011082257 t2= -0.4889394610199755 t3= 47.045379923312694 Multi_Loss= 151.53007224848895\n",
            "t1= 6.101351707599013 t2= -0.49370259912954767 t3= 47.04526075853356 Multi_Loss= 152.02072227602204\n",
            "t1= 6.096890906282632 t2= -0.4982411944561914 t3= 47.045162100772345 Multi_Loss= 152.48991984776677\n",
            "t1= 6.092484486112799 t2= -0.5025636126316793 t3= 47.04504604769272 Multi_Loss= 152.9383118868632\n",
            "t1= 6.088131763318102 t2= -0.5066820842553224 t3= 47.04500170006395 Multi_Loss= 153.36697297954655\n",
            "t1= 6.083828794474554 t2= -0.5105981231895919 t3= 47.04480597786254 Multi_Loss= 153.77586869852016\n",
            "t1= 6.079580009134401 t2= -0.5143384760124574 t3= 47.04502250702078 Multi_Loss= 154.1676474084056\n",
            "t1= 6.0753686729049985 t2= -0.5178642152176441 t3= 47.044188162201834 Multi_Loss= 154.53802233976182\n",
            "t1= 6.0712334685207185 t2= -0.521303706390803 t3= 47.04616958900436 Multi_Loss= 154.90047055832932\n",
            "t1= 6.067065528888095 t2= -0.5243262955427449 t3= 47.04052757376488 Multi_Loss= 155.21967602278897\n",
            "t1= 6.063154184523172 t2= -0.5277285280113935 t3= 47.05571458001371 Multi_Loss= 155.58041200580936\n",
            "t1= 6.058684383503034 t2= -0.5283936926036918 t3= 47.013205596593615 Multi_Loss= 155.64967852964463\n",
            "t1= 6.055649419036883 t2= -0.5282668607056865 t3= 47.09332788346901 Multi_Loss= 155.63506632603918\n",
            "t1= 6.049850464289459 t2= -0.5124249948633532 t3= 46.99505526695178 Multi_Loss= 153.94805272770463\n",
            "t1= 6.046950270388571 t2= -0.5084059591883184 t3= 47.05585439185194 Multi_Loss= 153.52134214849463\n",
            "t1= 6.0425029973749815 t2= -0.5099703116659507 t3= 47.01882089772314 Multi_Loss= 153.68460765086567\n",
            "t1= 6.039334298928874 t2= -0.5118348604257952 t3= 47.08997393342258 Multi_Loss= 153.88067485493593\n",
            "t1= 6.0337114317988 t2= -0.4989580304947606 t3= 46.99609106445405 Multi_Loss= 152.51746607468547\n",
            "t1= 6.030819753762863 t2= -0.4957777626406012 t3= 47.0558846741779 Multi_Loss= 152.18119806100233\n",
            "t1= 6.026425782491208 t2= -0.49792576490057394 t3= 47.02269773960647 Multi_Loss= 152.40490560354715\n",
            "t1= 6.023191499413421 t2= -0.5009475889126094 t3= 47.0862824745238 Multi_Loss= 152.72197065269378\n",
            "t1= 6.017764794722522 t2= -0.4906588999186836 t3= 46.996244849949775 Multi_Loss= 151.63610406587895\n",
            "t1= 6.014918210897248 t2= -0.48783876560430056 t3= 47.05446318374325 Multi_Loss= 151.33859756193635\n",
            "t1= 6.010649689956578 t2= -0.490678243724899 t3= 47.0283493412291 Multi_Loss= 151.6344699661253\n",
            "t1= 6.007320956625635 t2= -0.49473764479002347 t3= 47.08031180959957 Multi_Loss= 152.06012448130502\n",
            "t1= 6.0021754742562115 t2= -0.4876357728346457 t3= 46.99544834232268 Multi_Loss= 151.31075968718523\n",
            "t1= 5.999410660377678 t2= -0.4846860129544696 t3= 47.05147987076989 Multi_Loss= 150.99987024688812\n",
            "t1= 5.99534147904842 t2= -0.4882435606129934 t3= 47.036092970664164 Multi_Loss= 151.3715675127828\n",
            "t1= 5.991860085130089 t2= -0.49287555168050207 t3= 47.068622302100124 Multi_Loss= 151.8579189028326\n",
            "t1= 5.98722390053621 t2= -0.4908604304793233 t3= 47.0026597775254 Multi_Loss= 151.64392407027594\n",
            "t1= 5.984542108273184 t2= -0.48935660148622523 t3= 47.07077977100051 Multi_Loss= 151.48458997953566\n",
            "t1= 5.979863952582595 t2= -0.48669215662761806 t3= 47.002021498672036 Multi_Loss= 151.202518879059\n",
            "t1= 5.9772062318390065 t2= -0.48518717290854363 t3= 47.06843051214419 Multi_Loss= 151.04330636373405\n",
            "t1= 5.972649191305025 t2= -0.4836902864490965 t3= 47.006386309908436 Multi_Loss= 150.8843970913254\n",
            "t1= 5.969975168125657 t2= -0.4833631803358173 t3= 47.07613603705087 Multi_Loss= 150.84915061050805\n",
            "t1= 5.965186835474626 t2= -0.4788506661732893 t3= 47.00175809667814 Multi_Loss= 150.37361678899126\n",
            "t1= 5.962572004887428 t2= -0.47757174452962786 t3= 47.066046476955705 Multi_Loss= 150.23857042041487\n",
            "t1= 5.9581734946353535 t2= -0.47737381205658547 t3= 47.01266091472645 Multi_Loss= 150.21639811808362\n",
            "t1= 5.955461438714123 t2= -0.4787644782778899 t3= 47.0825279913276 Multi_Loss= 150.36161121164915\n",
            "t1= 5.950548325260274 t2= -0.4718172509408978 t3= 47.00507659222548 Multi_Loss= 149.63161314338794\n",
            "t1= 5.947950609246886 t2= -0.47159031128412215 t3= 47.07119430689529 Multi_Loss= 149.60703334571866\n",
            "t1= 5.943445250319484 t2= -0.4698345220975251 t3= 47.009952019337526 Multi_Loss= 149.42186063994856\n",
            "t1= 5.940820296485883 t2= -0.470832764378406 t3= 47.07820459409556 Multi_Loss= 149.52563238144617\n",
            "t1= 5.936122666655478 t2= -0.46629607976726156 t3= 47.00772360110702 Multi_Loss= 149.0495737648116\n",
            "t1= 5.933550935154971 t2= -0.4668764223996174 t3= 47.07442363097361 Multi_Loss= 149.1095361504079\n",
            "t1= 5.929015843833452 t2= -0.4641428593594316 t3= 47.01035113584365 Multi_Loss= 148.8225165890717\n",
            "t1= 5.926440467842766 t2= -0.465402940050946 t3= 47.07753951101189 Multi_Loss= 148.95359354057183\n",
            "t1= 5.921845175763354 t2= -0.4615063680358144 t3= 47.01043677322767 Multi_Loss= 148.5452124415425\n",
            "t1= 5.919297367549297 t2= -0.4628605414309343 t3= 47.077123623609666 Multi_Loss= 148.6860829370227\n",
            "t1= 5.914755921105958 t2= -0.4593009601836796 t3= 47.01172784867271 Multi_Loss= 148.31321677174836\n",
            "t1= 5.9122200948457175 t2= -0.4610102624233254 t3= 47.07815084146573 Multi_Loss= 148.49118902286523\n",
            "t1= 5.9076873399159835 t2= -0.45715724445125583 t3= 47.012656515372726 Multi_Loss= 148.0879073931944\n",
            "t1= 5.905168512809983 t2= -0.459130500479925 t3= 47.078686634149705 Multi_Loss= 148.29343846105286\n",
            "t1= 5.900660312206243 t2= -0.4551859701041471 t3= 47.01366163576761 Multi_Loss= 147.88083023113217\n",
            "t1= 5.898157552604381 t2= -0.4574290818042927 t3= 47.07924274451872 Multi_Loss= 148.1145430767388\n",
            "t1= 5.893673662822305 t2= -0.45337366138012997 t3= 47.01462605099512 Multi_Loss= 147.69055988402616\n",
            "t1= 5.891187842555804 t2= -0.4558662868160711 t3= 47.07970785015045 Multi_Loss= 147.95034154676193\n",
            "t1= 5.886731360437936 t2= -0.4517278119942229 t3= 47.0155464673794 Multi_Loss= 147.51786370890792\n",
            "t1= 5.8842635154110985 t2= -0.4544489111057976 t3= 47.08009452474534 Multi_Loss= 147.80153661256048\n",
            "t1= 5.879837047541551 t2= -0.4502491982653643 t3= 47.01640868231844 Multi_Loss= 147.36281208923157\n",
            "t1= 5.877388538274112 t2= -0.4531751336182383 t3= 47.08040798566438 Multi_Loss= 147.66793360604248\n",
            "t1= 5.872994431467545 t2= -0.44893359824190265 t3= 47.01720483084072 Multi_Loss= 147.2249582656783\n",
            "t1= 5.870566811711665 t2= -0.45203994688048355 t3= 47.08065879221172 Multi_Loss= 147.54900766619414\n",
            "t1= 5.866207001174011 t2= -0.447771788532225 t3= 47.01793283602019 Multi_Loss= 147.1033376913143\n",
            "t1= 5.863801878999666 t2= -0.45103487982502277 t3= 47.0808594491892 Multi_Loss= 147.44387426187643\n",
            "t1= 5.859477842099353 t2= -0.4467506738532093 t3= 47.01859540565146 Multi_Loss= 146.9965849471279\n",
            "t1= 5.85709675520639 t2= -0.4501487317980537 t3= 47.08102205893044 Multi_Loss= 147.3513650913501\n",
            "t1= 5.852809535944666 t2= -0.44585489906903936 t3= 47.01919829823155 Multi_Loss= 146.90310067611424\n",
            "t1= 5.850453864734012 t2= -0.44936866596335723 t3= 47.081156859474945 Multi_Loss= 147.27014144479944\n",
            "t1= 5.846204140773367 t2= -0.44506841976309214 t3= 47.01974864886659 Multi_Loss= 146.8212142256905\n",
            "t1= 5.843875063194509 t2= -0.44868133142836536 t3= 47.081271727325344 Multi_Loss= 147.1988106712315\n",
            "t1= 5.8396632262229895 t2= -0.444375710144142 t3= 47.020253763118575 Multi_Loss= 146.74930872510114\n",
            "t1= 5.837361705974355 t2= -0.4480737740385908 t3= 47.08137232585743 Multi_Loss= 147.13602078651274\n",
            "t1= 5.833187936270401 t2= -0.44376252304961067 t3= 47.02072042462324 Multi_Loss= 146.685899781763\n",
            "t1= 5.830914732379189 t2= -0.44753404298498983 t3= 47.08146253565961 Multi_Loss= 147.08052354703474\n",
            "t1= 5.8267790593908835 t2= -0.4432162638650267 t3= 47.021154587930916 Multi_Loss= 146.62967420963616\n",
            "t1= 5.8245347469528195 t2= -0.4470515116204612 t3= 47.08154492593801 Multi_Loss= 147.03120787321464\n",
            "t1= 5.820437094829327 t2= -0.44272609029796317 t3= 47.021561305357345 Multi_Loss= 146.57950038402925\n",
            "t1= 5.818222089962503 t2= -0.44661698151233176 t3= 47.08162115709289 Multi_Loss= 146.98711077145208\n",
            "t1= 5.814162310193079 t2= -0.44228284354705527 t3= 47.02194477500792 Multi_Loss= 146.53442114717927\n",
            "t1= 5.8119768951288036 t2= -0.44622264525474037 t3= 47.08169228604818 Multi_Loss= 146.9474135835886\n",
            "t1= 5.807954789266949 t2= -0.4418788902244713 t3= 47.02230844091738 Multi_Loss= 146.49363747491935\n",
            "t1= 5.80579913548085 t2= -0.4458619697758853 t3= 47.081758982551726 Multi_Loss= 146.9114299660951\n",
            "t1= 5.801814470683481 t2= -0.4415079276241434 t3= 47.02265510773401 Multi_Loss= 146.4564883440226\n",
            "t1= 5.799688659180741 t2= -0.4455295435488372 t3= 47.08182167572769 Multi_Loss= 146.87859010251975\n",
            "t1= 5.795741178721625 t2= -0.4411647840677029 t3= 47.022987051385975 Multi_Loss= 146.42243008221106\n",
            "t1= 5.793645217272599 t2= -0.4452209152024541 t3= 47.08188065010869 Multi_Loss= 146.84842400374592\n",
            "t1= 5.789734647618899 t2= -0.4408452316976775 t3= 47.02330611768156 Multi_Loss= 146.39101699809177\n",
            "t1= 5.787668485095984 t2= -0.444932439334535 t3= 47.08193610674026 Multi_Loss= 146.82054553848963\n",
            "t1= 5.783794540670638 t2= -0.44054581991827285 t3= 47.023613806296844 Multi_Loss= 146.36188414061183\n",
            "t1= 5.781758078799534 t2= -0.444661137508936 t3= 47.08198820089666 Multi_Loss= 146.79463802558672\n",
            "t1= 5.777920465203265 t2= -0.44026373217589404 t3= 47.02391134032775 Multi_Loss= 146.3347324682598\n",
            "t1= 5.775913568095829 t2= -0.44440457753838175 t3= 47.08203706453267 Multi_Loss= 146.77044171329405\n",
            "t1= 5.772111984312991 t2= -0.43999666567589285 t3= 47.024199722808945 Multi_Loss= 146.3093163880439\n",
            "t1= 5.770134486145218 t2= -0.4441607713059132 t3= 47.082082819012754 Multi_Loss= 146.74774317489283\n",
            "t1= 5.766368626083963 t2= -0.4397427320544039 t3= 47.02447978204111 Multi_Loss= 146.2854334608747\n",
            "t1= 5.764420337250744 t2= -0.44392808985312776 t3= 47.082125581810104 Multi_Loss= 146.72636649115717\n",
            "t1= 5.7606898908492115 t2= -0.4395003763629488 t3= 47.02475220760549 Multi_Loss= 146.26291600124554\n",
            "t1= 5.7587706028843035 t2= -0.4437051937615409 t3= 47.08216546958718 Multi_Loss= 146.70616601687\n",
            "t1= 5.755075256934376 t2= -0.4392683115891519 t3= 47.02501757879327 Multi_Loss= 146.24162428485812\n",
            "t1= 5.753184746438752 t2= -0.4434909766389718 t3= 47.0822025992005 Multi_Loss= 146.68702050579373\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What do you think is happening? Try different initial values and learning rates, and see if you get better results. Go back to the slides (slide  26) to get some insight and see if you can explain what is happening here.\n",
        "\n",
        "Use the rest of the notebook to do your own gradient descent problem!"
      ],
      "metadata": {
        "id": "7oV9P_-GzkPl"
      }
    }
  ]
}